{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from Metric import get_uplift_model_aucc\n",
    "from model import slearner_criteo_uplift\n",
    "from utils import * \n",
    "from Lagrangian_duality_gradient_estimator import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_criteo = pd.read_csv('data/criteo-uplift-v2.1.csv', sep=',')\n",
    "\n",
    "random_state = 20220720\n",
    "df_criteo = df_criteo.sample(frac=1.0, random_state=random_state).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>treatment</th>\n",
       "      <th>conversion</th>\n",
       "      <th>visit</th>\n",
       "      <th>exposure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.616365</td>\n",
       "      <td>10.059654</td>\n",
       "      <td>8.859005</td>\n",
       "      <td>4.679882</td>\n",
       "      <td>10.280525</td>\n",
       "      <td>4.115453</td>\n",
       "      <td>0.294443</td>\n",
       "      <td>4.833815</td>\n",
       "      <td>3.910792</td>\n",
       "      <td>13.190056</td>\n",
       "      <td>5.300375</td>\n",
       "      <td>-0.168679</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.527349</td>\n",
       "      <td>10.059654</td>\n",
       "      <td>8.214383</td>\n",
       "      <td>4.679882</td>\n",
       "      <td>10.280525</td>\n",
       "      <td>4.115453</td>\n",
       "      <td>-2.411115</td>\n",
       "      <td>4.833815</td>\n",
       "      <td>3.971858</td>\n",
       "      <td>13.190056</td>\n",
       "      <td>5.300375</td>\n",
       "      <td>-0.168679</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.753301</td>\n",
       "      <td>10.059654</td>\n",
       "      <td>8.214383</td>\n",
       "      <td>4.679882</td>\n",
       "      <td>10.280525</td>\n",
       "      <td>4.115453</td>\n",
       "      <td>-1.288207</td>\n",
       "      <td>4.833815</td>\n",
       "      <td>3.971858</td>\n",
       "      <td>13.190056</td>\n",
       "      <td>5.300375</td>\n",
       "      <td>-0.168679</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.544662</td>\n",
       "      <td>10.059654</td>\n",
       "      <td>8.214383</td>\n",
       "      <td>4.679882</td>\n",
       "      <td>10.280525</td>\n",
       "      <td>4.115453</td>\n",
       "      <td>-3.282109</td>\n",
       "      <td>4.833815</td>\n",
       "      <td>3.971858</td>\n",
       "      <td>13.190056</td>\n",
       "      <td>5.300375</td>\n",
       "      <td>-0.168679</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.311796</td>\n",
       "      <td>10.059654</td>\n",
       "      <td>8.214383</td>\n",
       "      <td>4.679882</td>\n",
       "      <td>10.280525</td>\n",
       "      <td>4.115453</td>\n",
       "      <td>-1.288207</td>\n",
       "      <td>4.833815</td>\n",
       "      <td>3.971858</td>\n",
       "      <td>13.190056</td>\n",
       "      <td>5.300375</td>\n",
       "      <td>-0.168679</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13979587</th>\n",
       "      <td>12.616365</td>\n",
       "      <td>10.059654</td>\n",
       "      <td>8.868975</td>\n",
       "      <td>4.679882</td>\n",
       "      <td>10.280525</td>\n",
       "      <td>4.115453</td>\n",
       "      <td>0.294443</td>\n",
       "      <td>4.833815</td>\n",
       "      <td>3.876391</td>\n",
       "      <td>13.190056</td>\n",
       "      <td>5.300375</td>\n",
       "      <td>-0.168679</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13979588</th>\n",
       "      <td>14.974642</td>\n",
       "      <td>10.059654</td>\n",
       "      <td>8.214383</td>\n",
       "      <td>3.907662</td>\n",
       "      <td>10.280525</td>\n",
       "      <td>4.115453</td>\n",
       "      <td>-8.493011</td>\n",
       "      <td>4.833815</td>\n",
       "      <td>3.971858</td>\n",
       "      <td>13.190056</td>\n",
       "      <td>5.300375</td>\n",
       "      <td>-0.168679</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13979589</th>\n",
       "      <td>14.461671</td>\n",
       "      <td>10.679513</td>\n",
       "      <td>8.214383</td>\n",
       "      <td>0.604065</td>\n",
       "      <td>10.280525</td>\n",
       "      <td>2.230907</td>\n",
       "      <td>-11.858523</td>\n",
       "      <td>7.900615</td>\n",
       "      <td>3.971858</td>\n",
       "      <td>13.190056</td>\n",
       "      <td>5.300375</td>\n",
       "      <td>-0.168679</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13979590</th>\n",
       "      <td>13.717872</td>\n",
       "      <td>10.059654</td>\n",
       "      <td>8.280712</td>\n",
       "      <td>2.587543</td>\n",
       "      <td>10.280525</td>\n",
       "      <td>4.115453</td>\n",
       "      <td>-17.661325</td>\n",
       "      <td>4.833815</td>\n",
       "      <td>3.800545</td>\n",
       "      <td>31.144700</td>\n",
       "      <td>5.300375</td>\n",
       "      <td>-0.168679</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13979591</th>\n",
       "      <td>26.554189</td>\n",
       "      <td>10.059654</td>\n",
       "      <td>8.214383</td>\n",
       "      <td>4.679882</td>\n",
       "      <td>10.280525</td>\n",
       "      <td>4.115453</td>\n",
       "      <td>-10.403862</td>\n",
       "      <td>4.833815</td>\n",
       "      <td>3.971858</td>\n",
       "      <td>13.190056</td>\n",
       "      <td>5.300375</td>\n",
       "      <td>-0.168679</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13979592 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 f0         f1        f2        f3         f4        f5  \\\n",
       "0         12.616365  10.059654  8.859005  4.679882  10.280525  4.115453   \n",
       "1         25.527349  10.059654  8.214383  4.679882  10.280525  4.115453   \n",
       "2         24.753301  10.059654  8.214383  4.679882  10.280525  4.115453   \n",
       "3         24.544662  10.059654  8.214383  4.679882  10.280525  4.115453   \n",
       "4         26.311796  10.059654  8.214383  4.679882  10.280525  4.115453   \n",
       "...             ...        ...       ...       ...        ...       ...   \n",
       "13979587  12.616365  10.059654  8.868975  4.679882  10.280525  4.115453   \n",
       "13979588  14.974642  10.059654  8.214383  3.907662  10.280525  4.115453   \n",
       "13979589  14.461671  10.679513  8.214383  0.604065  10.280525  2.230907   \n",
       "13979590  13.717872  10.059654  8.280712  2.587543  10.280525  4.115453   \n",
       "13979591  26.554189  10.059654  8.214383  4.679882  10.280525  4.115453   \n",
       "\n",
       "                 f6        f7        f8         f9       f10       f11  \\\n",
       "0          0.294443  4.833815  3.910792  13.190056  5.300375 -0.168679   \n",
       "1         -2.411115  4.833815  3.971858  13.190056  5.300375 -0.168679   \n",
       "2         -1.288207  4.833815  3.971858  13.190056  5.300375 -0.168679   \n",
       "3         -3.282109  4.833815  3.971858  13.190056  5.300375 -0.168679   \n",
       "4         -1.288207  4.833815  3.971858  13.190056  5.300375 -0.168679   \n",
       "...             ...       ...       ...        ...       ...       ...   \n",
       "13979587   0.294443  4.833815  3.876391  13.190056  5.300375 -0.168679   \n",
       "13979588  -8.493011  4.833815  3.971858  13.190056  5.300375 -0.168679   \n",
       "13979589 -11.858523  7.900615  3.971858  13.190056  5.300375 -0.168679   \n",
       "13979590 -17.661325  4.833815  3.800545  31.144700  5.300375 -0.168679   \n",
       "13979591 -10.403862  4.833815  3.971858  13.190056  5.300375 -0.168679   \n",
       "\n",
       "          treatment  conversion  visit  exposure  \n",
       "0                 1           0      0         0  \n",
       "1                 0           0      0         0  \n",
       "2                 1           0      0         0  \n",
       "3                 1           0      0         0  \n",
       "4                 1           0      0         0  \n",
       "...             ...         ...    ...       ...  \n",
       "13979587          1           0      0         0  \n",
       "13979588          1           0      0         0  \n",
       "13979589          1           0      0         0  \n",
       "13979590          1           0      0         0  \n",
       "13979591          1           0      0         0  \n",
       "\n",
       "[13979592 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_criteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "T = df_criteo['treatment'].values.reshape(-1, 1)\n",
    "unique, counts = np.unique(T, return_counts=True)\n",
    "weights = counts / len(T)\n",
    "\n",
    "train_dl, X_val, T_val, Y_visit_val, Y_visit_float_val, Y_conv_val, Y_conv_float_val, X_test, T_test, Y_visit_test, Y_visit_float_test, Y_conv_test, Y_conv_float_test = get_data(df_criteo, weights, unique, 300000, 30) \n",
    "weights = torch.tensor(weights).cuda()\n",
    "X_val, T_val, Y_visit_val, Y_visit_float_val, Y_conv_val, Y_conv_float_val = X_val.cuda(), T_val.cuda(), Y_visit_val.cuda(), Y_visit_float_val.cuda(), Y_conv_val.cuda(), Y_conv_float_val.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_aucc:0.7576427022361585\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    model_ts_best = slearner_criteo_uplift(12, 4)\n",
    "    model_ts_best.load_state_dict(torch.load('Model/model_before_finetune.pkl'))\n",
    "    T1 = torch.ones_like(T_test)\n",
    "    T0 = torch.zeros_like(T_test)\n",
    "    y_visit_pred_T0, y_visit_pred_T1, y_conv_pred_T0, y_conv_pred_T1 = model_ts_best(X_test, T0, T1)\n",
    "    conv_pred = y_conv_pred_T1 - y_conv_pred_T0\n",
    "    visit_pred = y_visit_pred_T1 - y_visit_pred_T0\n",
    "    conv_pred = conv_pred.numpy()\n",
    "    visit_pred =  visit_pred.numpy()\n",
    "    roi_pred = conv_pred / np.where(abs(visit_pred) < 1e-6, 1e-6, visit_pred)\n",
    "    test_aucc_ts = get_uplift_model_aucc(t=(T_test.numpy() > 0.5).flatten(), yr=Y_conv_test.numpy().flatten(), yc=Y_visit_test.numpy().flatten(), roi_pred=roi_pred.flatten(), quantile=200)\n",
    "    print(f'test_aucc:{test_aucc_ts[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------epoch: 1/10------val_aucc:0.7190463173960582------test_aucc:0.7712565579734362------\n",
      "------epoch: 2/10------val_aucc:0.716319472628475------test_aucc:0.7812341761551967------\n",
      "------epoch: 3/10------val_aucc:0.7167091869075032------test_aucc:0.7859922524091434------\n",
      "------epoch: 4/10------val_aucc:0.7218673560607439------test_aucc:0.7883989543843595------\n",
      "------epoch: 5/10------val_aucc:0.723380065219531------test_aucc:0.7859323088843684------\n",
      "------epoch: 6/10------val_aucc:0.7287265969330889------test_aucc:0.7870811410225322------\n",
      "------epoch: 7/10------val_aucc:0.7306692934497881------test_aucc:0.7867055580705133------\n",
      "------epoch: 8/10------val_aucc:0.726489715710019------test_aucc:0.7885779061475281------\n",
      "------epoch: 9/10------val_aucc:0.7295609281811093------test_aucc:0.7875434116891156------\n",
      "------epoch: 10/10------val_aucc:0.7268940863927515------test_aucc:0.787456024835904------\n",
      "------ifd finetune finished!------val_aucc:0.7306692934497881------test_aucc:0.7867055580705133\n"
     ]
    }
   ],
   "source": [
    "#Improved Finite-Difference Strategy\n",
    "lambda_1 = 0.1\n",
    "max_val_aucc = 0\n",
    "num_epoch = 10\n",
    "h = 0.3\n",
    "model_ifd = slearner_criteo_uplift(12, 4).cuda()\n",
    "model_ifd.load_state_dict(torch.load('Model/model_before_finetune.pkl'))\n",
    "optimizer = optim.Adam(model_ifd.parameters(), lr=1e-5, weight_decay=1e-5)\n",
    "for epoch in range(num_epoch):\n",
    "    for data in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        x, t, y_visit, y_visit_float, y_conv, y_conv_float = data\n",
    "        x, t, y_visit, y_visit_float, y_conv, y_conv_float = x.cuda(), t.cuda(), y_visit.cuda(), y_visit_float.cuda(), y_conv.cuda(), y_conv_float.cuda()\n",
    "        row_idx = torch.arange(x.shape[0])\n",
    "        T1 = torch.ones_like(t).cuda()\n",
    "        T0 = torch.zeros_like(t).cuda()\n",
    "        y_visit_pred_T0, y_visit_pred_T1, y_conv_pred_T0, y_conv_pred_T1 = model_ifd(x, T0, T1)\n",
    "        r_hat = torch.cat([y_conv_pred_T0, y_conv_pred_T1], dim=1)\n",
    "        c_hat = torch.cat([y_visit_pred_T0, y_visit_pred_T1], dim=1)\n",
    "        idx_T0 = torch.where(t==0)[0]\n",
    "        idx_T1 = torch.where(t==1)[0]\n",
    "        \n",
    "        \n",
    "        dQ_dr1, dQ_dc1 = improved_finite_difference(t=t, yr=y_conv_float, yc=y_visit_float, r_hat=r_hat, c_hat=c_hat, lambda_=lambda_1, weights=weights, h=h, clip='fix')\n",
    "\n",
    "        dQ_dr1, dQ_dc1 = dQ_dr1.detach(), dQ_dc1.detach()\n",
    "\n",
    "        loss_dfl = -torch.matmul(r_hat.t(), dQ_dr1).trace()\n",
    "\n",
    "        loss = loss_dfl\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_ifd = model_ifd.cpu()\n",
    "        T1 = torch.ones_like(T_test)\n",
    "        T0 = torch.zeros_like(T_test)\n",
    "        y_visit_pred_T0, y_visit_pred_T1, y_conv_pred_T0, y_conv_pred_T1 = model_ifd(X_test, T0, T1)\n",
    "        conv_pred = y_conv_pred_T1 - y_conv_pred_T0\n",
    "        visit_pred = y_visit_pred_T1 - y_visit_pred_T0\n",
    "        conv_pred = conv_pred.numpy()\n",
    "        visit_pred =  visit_pred.numpy()\n",
    "        roi_pred = conv_pred / np.where(abs(visit_pred) < 1e-6, 1e-6, visit_pred)\n",
    "        test_aucc = get_uplift_model_aucc(t=(T_test.numpy() > 0.5).flatten(), yr=Y_conv_test.numpy().flatten(), yc=Y_visit_test.numpy().flatten(), roi_pred=roi_pred.flatten(), quantile=200)\n",
    "        model_ifd = model_ifd.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        T1 = torch.ones_like(T_val).cuda()\n",
    "        T0 = torch.zeros_like(T_val).cuda()\n",
    "        y_visit_pred_T0, y_visit_pred_T1, y_conv_pred_T0, y_conv_pred_T1 = model_ifd(X_val, T0, T1)\n",
    "        conv_pred = y_conv_pred_T1 - y_conv_pred_T0\n",
    "        visit_pred = y_visit_pred_T1 - y_visit_pred_T0\n",
    "        conv_pred = conv_pred.cpu().numpy()\n",
    "        visit_pred =  visit_pred.cpu().numpy()\n",
    "        roi_pred = conv_pred / np.where(abs(visit_pred) < 1e-6, 1e-6, visit_pred)\n",
    "        val_aucc = get_uplift_model_aucc(t=(T_val.cpu().numpy() > 0.5).flatten(), yr=Y_conv_val.cpu().numpy().flatten(), yc=Y_visit_val.cpu().numpy().flatten(), roi_pred=roi_pred.flatten(), quantile=200)\n",
    "        if val_aucc[0] > max_val_aucc:\n",
    "            max_val_aucc = val_aucc[0]\n",
    "            torch.save(model_ifd.state_dict(), 'Model/model_ifd.pkl')\n",
    "    \n",
    "    print(f'------epoch: {epoch+1}/{num_epoch}------val_aucc:{val_aucc[0]}------test_aucc:{test_aucc[0]}------')\n",
    "    \n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_ifd_best = slearner_criteo_uplift(12, 4)\n",
    "    model_ifd_best.load_state_dict(torch.load('Model/model_ifd.pkl'))\n",
    "    T1 = torch.ones_like(T_test)\n",
    "    T0 = torch.zeros_like(T_test)\n",
    "    y_visit_pred_T0, y_visit_pred_T1, y_conv_pred_T0, y_conv_pred_T1 = model_ifd_best(X_test, T0, T1)\n",
    "    conv_pred = y_conv_pred_T1 - y_conv_pred_T0\n",
    "    visit_pred = y_visit_pred_T1 - y_visit_pred_T0\n",
    "    conv_pred = conv_pred.numpy()\n",
    "    visit_pred =  visit_pred.numpy()\n",
    "    roi_pred = conv_pred / np.where(abs(visit_pred) < 1e-6, 1e-6, visit_pred)\n",
    "    test_aucc_ifd = get_uplift_model_aucc(t=(T_test.numpy() > 0.5).flatten(), yr=Y_conv_test.numpy().flatten(), yc=Y_visit_test.numpy().flatten(), roi_pred=roi_pred.flatten(), quantile=200)\n",
    "    print(f'------ifd finetune finished!------val_aucc:{max_val_aucc}------test_aucc:{test_aucc_ifd[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------epoch: 1/10------val_aucc:0.7168119417098112------test_aucc:0.7672649371999091------\n",
      "------epoch: 2/10------val_aucc:0.7284346157656674------test_aucc:0.7711795785830728------\n",
      "------epoch: 3/10------val_aucc:0.7444387639114133------test_aucc:0.7731270850803473------\n",
      "------epoch: 4/10------val_aucc:0.7406242648678697------test_aucc:0.7810324514832432------\n",
      "------epoch: 5/10------val_aucc:0.7380698593422175------test_aucc:0.7784797118918335------\n",
      "------epoch: 6/10------val_aucc:0.7343664459895957------test_aucc:0.7711996630116295------\n",
      "------epoch: 7/10------val_aucc:0.7387630541330382------test_aucc:0.7719952732978091------\n",
      "------epoch: 8/10------val_aucc:0.7376575656599017------test_aucc:0.7684554773237533------\n",
      "------epoch: 9/10------val_aucc:0.7412883475165682------test_aucc:0.7667677934624005------\n",
      "------epoch: 10/10------val_aucc:0.7423403675286265------test_aucc:0.7637412063787674------\n",
      "------pl finetune finished!------val_aucc:0.7444387639114133------test_aucc:0.7731270850803473\n"
     ]
    }
   ],
   "source": [
    "#Policy Learning Loss\n",
    "lambda_1 = 0.1\n",
    "max_val_aucc = 0\n",
    "aucc_list = []\n",
    "model_pl = slearner_criteo_uplift(12, 4).cuda()\n",
    "model_pl.load_state_dict(torch.load('Model/model_before_finetune.pkl'))\n",
    "optimizer = optim.Adam(model_pl.parameters(), lr=1e-5, weight_decay=1e-5)\n",
    "for epoch in range(num_epoch):\n",
    "    count = 0\n",
    "    for data in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        x, t, y_visit, y_visit_float, y_conv, y_conv_float = data\n",
    "        x, t, y_visit, y_visit_float, y_conv, y_conv_float = x.cuda(), t.cuda(), y_visit.cuda(), y_visit_float.cuda(), y_conv.cuda(), y_conv_float.cuda()\n",
    "        row_idx = torch.arange(x.shape[0])\n",
    "        \n",
    "        T1 = torch.ones_like(t).cuda()\n",
    "        T0 = torch.zeros_like(t).cuda()\n",
    "        y_visit_pred_T0, y_visit_pred_T1, y_conv_pred_T0, y_conv_pred_T1 = model_pl(x, T0, T1)\n",
    "        t = t.squeeze()\n",
    "        r = torch.cat([y_conv_pred_T0, y_conv_pred_T1], dim=1)\n",
    "        c = torch.cat([y_visit_pred_T0, y_visit_pred_T1], dim=1)\n",
    "        idx_T0 = torch.where(t==0)[0]\n",
    "        idx_T1 = torch.where(t==1)[0]\n",
    "        \n",
    "        \n",
    "        a1 = nn.functional.softmax(r-lambda_1*c, dim=1)\n",
    "\n",
    "        loss_dfl = - torch.mean((y_conv - lambda_1*y_visit).squeeze().detach() * a1[row_idx, t.long()])\n",
    "\n",
    "        loss = loss_dfl\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_pl = model_pl.cpu()\n",
    "        T1 = torch.ones_like(T_test)\n",
    "        T0 = torch.zeros_like(T_test)\n",
    "        y_visit_pred_T0, y_visit_pred_T1, y_conv_pred_T0, y_conv_pred_T1 = model_pl(X_test, T0, T1)\n",
    "        conv_pred = y_conv_pred_T1 - y_conv_pred_T0\n",
    "        visit_pred = y_visit_pred_T1 - y_visit_pred_T0\n",
    "        conv_pred = conv_pred.numpy()\n",
    "        visit_pred =  visit_pred.numpy()\n",
    "        roi_pred = conv_pred / np.where(abs(visit_pred) < 1e-6, 1e-6, visit_pred)\n",
    "        test_aucc = get_uplift_model_aucc(t=(T_test.numpy() > 0.5).flatten(), yr=Y_conv_test.numpy().flatten(), yc=Y_visit_test.numpy().flatten(), roi_pred=roi_pred.flatten(), quantile=200)\n",
    "        model_pl = model_pl.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        T1 = torch.ones_like(T_val).cuda()\n",
    "        T0 = torch.zeros_like(T_val).cuda()\n",
    "        y_visit_pred_T0, y_visit_pred_T1, y_conv_pred_T0, y_conv_pred_T1 = model_pl(X_val, T0, T1)\n",
    "        conv_pred = y_conv_pred_T1 - y_conv_pred_T0\n",
    "        visit_pred = y_visit_pred_T1 - y_visit_pred_T0\n",
    "        conv_pred = conv_pred.cpu().numpy()\n",
    "        visit_pred =  visit_pred.cpu().numpy()\n",
    "        roi_pred = conv_pred / np.where(abs(visit_pred) < 1e-6, 1e-6, visit_pred)\n",
    "        val_aucc = get_uplift_model_aucc(t=(T_val.cpu().numpy() > 0.5).flatten(), yr=Y_conv_val.cpu().numpy().flatten(), yc=Y_visit_val.cpu().numpy().flatten(), roi_pred=roi_pred.flatten(), quantile=200)\n",
    "        if val_aucc[0] > max_val_aucc:\n",
    "            max_val_aucc = val_aucc[0]\n",
    "            torch.save(model_pl.state_dict(), 'Model/model_pl.pkl')\n",
    "\n",
    "    print(f'------epoch: {epoch+1}/{num_epoch}------val_aucc:{val_aucc[0]}------test_aucc:{test_aucc[0]}------')\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_pl_best = slearner_criteo_uplift(12, 4)\n",
    "    model_pl_best.load_state_dict(torch.load('Model/model_pl.pkl'))\n",
    "    T1 = torch.ones_like(T_test)\n",
    "    T0 = torch.zeros_like(T_test)\n",
    "    y_visit_pred_T0, y_visit_pred_T1, y_conv_pred_T0, y_conv_pred_T1 = model_pl_best(X_test, T0, T1)\n",
    "    idx_T0 = torch.where(T_test==0)[0]\n",
    "    idx_T1 = torch.where(T_test==1)[0]\n",
    "    conv_pred = y_conv_pred_T1 - y_conv_pred_T0\n",
    "    visit_pred = y_visit_pred_T1 - y_visit_pred_T0\n",
    "    conv_pred = conv_pred.numpy()\n",
    "    visit_pred =  visit_pred.numpy()\n",
    "    roi_pred = conv_pred / np.where(abs(visit_pred) < 1e-6, 1e-6, visit_pred)\n",
    "    test_aucc_pl = get_uplift_model_aucc(t=(T_test.numpy() > 0.5).flatten(), yr=Y_conv_test.numpy().flatten(), yc=Y_visit_test.numpy().flatten(), roi_pred=roi_pred.flatten(), quantile=200)\n",
    "    print(f'------pl finetune finished!------val_aucc:{max_val_aucc}------test_aucc:{test_aucc_pl[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------epoch: 1/10------val_aucc:0.712076519788604------test_aucc:0.7688673565069325------\n",
      "------epoch: 2/10------val_aucc:0.7129747429755668------test_aucc:0.7748737176264008------\n",
      "------epoch: 3/10------val_aucc:0.71452045601545------test_aucc:0.7721834120693929------\n",
      "------epoch: 4/10------val_aucc:0.7145159549427909------test_aucc:0.7742032103773447------\n",
      "------epoch: 5/10------val_aucc:0.7259666608481063------test_aucc:0.7729711165156808------\n",
      "------epoch: 6/10------val_aucc:0.7304515334250161------test_aucc:0.7739996278884348------\n",
      "------epoch: 7/10------val_aucc:0.7292697607918609------test_aucc:0.7770062335607394------\n",
      "------epoch: 8/10------val_aucc:0.7362007953686206------test_aucc:0.7791914249737131------\n",
      "------epoch: 9/10------val_aucc:0.740817861401174------test_aucc:0.7793157537137336------\n",
      "------epoch: 10/10------val_aucc:0.7410326410185315------test_aucc:0.7816443538969104------\n",
      "------mer finetune finished!------val_aucc:0.7410326410185315------test_aucc:0.7816443538969104\n"
     ]
    }
   ],
   "source": [
    "#Maximum Entropy Regularized Loss\n",
    "lambda_1 = 0.1\n",
    "\n",
    "max_val_aucc = 0\n",
    "tau = 5\n",
    "aucc_list = []\n",
    "model_mer = slearner_criteo_uplift(12, 4).cuda()\n",
    "model_mer.load_state_dict(torch.load('Model/model_before_finetune.pkl'))\n",
    "optimizer = optim.Adam(model_mer.parameters(), lr=1e-5, weight_decay=1e-5)\n",
    "for epoch in range(num_epoch):\n",
    "    count = 0\n",
    "    for data in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        x, t, y_visit, y_visit_float, y_conv, y_conv_float = data\n",
    "        x, t, y_visit, y_visit_float, y_conv, y_conv_float = x.cuda(), t.cuda(), y_visit.cuda(), y_visit_float.cuda(), y_conv.cuda(), y_conv_float.cuda()\n",
    "        row_idx = torch.arange(x.shape[0])\n",
    "        \n",
    "        T1 = torch.ones_like(t).cuda()\n",
    "        T0 = torch.zeros_like(t).cuda()\n",
    "        y_visit_pred_T0, y_visit_pred_T1, y_conv_pred_T0, y_conv_pred_T1 = model_mer(x, T0, T1)\n",
    "        t = t.squeeze()\n",
    "        r = torch.cat([y_conv_pred_T0, y_conv_pred_T1], dim=1)\n",
    "        c = torch.cat([y_visit_pred_T0, y_visit_pred_T1], dim=1)\n",
    "        idx_T0 = torch.where(t==0)[0]\n",
    "        idx_T1 = torch.where(t==1)[0]\n",
    "        \n",
    "        \n",
    "        a1 = nn.functional.softmax((r-lambda_1*c)/tau, dim=1)\n",
    "\n",
    "        loss_dfl = - torch.mean((y_conv - lambda_1*y_visit).squeeze().detach() * a1[row_idx, t.long()])\n",
    "\n",
    "        loss = loss_dfl\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_mer = model_mer.cpu()\n",
    "        T1 = torch.ones_like(T_test)\n",
    "        T0 = torch.zeros_like(T_test)\n",
    "        y_visit_pred_T0, y_visit_pred_T1, y_conv_pred_T0, y_conv_pred_T1 = model_mer(X_test, T0, T1)\n",
    "        conv_pred = y_conv_pred_T1 - y_conv_pred_T0\n",
    "        visit_pred = y_visit_pred_T1 - y_visit_pred_T0\n",
    "        conv_pred = conv_pred.numpy()\n",
    "        visit_pred =  visit_pred.numpy()\n",
    "        roi_pred = conv_pred / np.where(abs(visit_pred) < 1e-6, 1e-6, visit_pred)\n",
    "        test_aucc = get_uplift_model_aucc(t=(T_test.numpy() > 0.5).flatten(), yr=Y_conv_test.numpy().flatten(), yc=Y_visit_test.numpy().flatten(), roi_pred=roi_pred.flatten(), quantile=200)\n",
    "        model_mer = model_mer.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        T1 = torch.ones_like(T_val).cuda()\n",
    "        T0 = torch.zeros_like(T_val).cuda()\n",
    "        y_visit_pred_T0, y_visit_pred_T1, y_conv_pred_T0, y_conv_pred_T1 = model_mer(X_val, T0, T1)\n",
    "        conv_pred = y_conv_pred_T1 - y_conv_pred_T0\n",
    "        visit_pred = y_visit_pred_T1 - y_visit_pred_T0\n",
    "        conv_pred = conv_pred.cpu().numpy()\n",
    "        visit_pred =  visit_pred.cpu().numpy()\n",
    "        roi_pred = conv_pred / np.where(abs(visit_pred) < 1e-6, 1e-6, visit_pred)\n",
    "        val_aucc = get_uplift_model_aucc(t=(T_val.cpu().numpy() > 0.5).flatten(), yr=Y_conv_val.cpu().numpy().flatten(), yc=Y_visit_val.cpu().numpy().flatten(), roi_pred=roi_pred.flatten(), quantile=200)\n",
    "        if val_aucc[0] > max_val_aucc:\n",
    "            max_val_aucc = val_aucc[0]\n",
    "            torch.save(model_mer.state_dict(), 'Model/model_mer.pkl')\n",
    "\n",
    "    print(f'------epoch: {epoch+1}/{num_epoch}------val_aucc:{val_aucc[0]}------test_aucc:{test_aucc[0]}------')\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_mer_best = slearner_criteo_uplift(12, 4)\n",
    "    model_mer_best.load_state_dict(torch.load('Model/model_mer.pkl'))\n",
    "    T1 = torch.ones_like(T_test)\n",
    "    T0 = torch.zeros_like(T_test)\n",
    "    y_visit_pred_T0, y_visit_pred_T1, y_conv_pred_T0, y_conv_pred_T1 = model_mer_best(X_test, T0, T1)\n",
    "    idx_T0 = torch.where(T_test==0)[0]\n",
    "    idx_T1 = torch.where(T_test==1)[0]\n",
    "    conv_pred = y_conv_pred_T1 - y_conv_pred_T0\n",
    "    visit_pred = y_visit_pred_T1 - y_visit_pred_T0\n",
    "    conv_pred = conv_pred.numpy()\n",
    "    visit_pred =  visit_pred.numpy()\n",
    "    roi_pred = conv_pred / np.where(abs(visit_pred) < 1e-6, 1e-6, visit_pred)\n",
    "    test_aucc_mer = get_uplift_model_aucc(t=(T_test.numpy() > 0.5).flatten(), yr=Y_conv_test.numpy().flatten(), yc=Y_visit_test.numpy().flatten(), roi_pred=roi_pred.flatten(), quantile=200)\n",
    "    print(f'------mer finetune finished!------val_aucc:{max_val_aucc}------test_aucc:{test_aucc_mer[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.rc('font', family='Times New Roman')\n",
    "\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['savefig.facecolor'] = 'white'\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(True)\n",
    "ax.spines['top'].set_color('black')\n",
    "ax.spines['top'].set_linewidth('1.5')\n",
    "\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['bottom'].set_linewidth('1.5')\n",
    "\n",
    "ax.spines['left'].set_visible(True)\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['left'].set_linewidth('1.5')\n",
    "\n",
    "\n",
    "ax.spines['right'].set_visible(True)\n",
    "ax.spines['right'].set_color('black')\n",
    "ax.spines['right'].set_linewidth('1.5')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_index = test_aucc_ts[1]\n",
    "y_random = test_aucc_ts[2][-1] / x_index[-1] * x_index\n",
    "\n",
    "x_normalization = x_index[-1]\n",
    "y_normalization = test_aucc_ts[2][-1]\n",
    "\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(x_index / x_normalization, test_aucc_ts[2] / y_normalization, color='#BB9727', label='TSM-SL', linewidth=2)\n",
    "plt.plot(x_index / x_normalization, test_aucc_ifd[2] / y_normalization, color='#F27970', label='DFCL-IFD', linewidth=2)\n",
    "plt.plot(x_index / x_normalization, test_aucc_pl[2] / y_normalization, color='#05B9E2', label='DFCL-PL', linewidth=2)\n",
    "plt.plot(x_index / x_normalization, test_aucc_mer[2] / y_normalization, color='#8983BF', label='DFCL-MER', linewidth=2)\n",
    "\n",
    "plt.plot(x_index / x_normalization, y_random / y_normalization, color='#000000', label='Random', linewidth=2)\n",
    "\n",
    "plt.xlabel('Incremental cost', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Incremental reward', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend(prop={'weight':\"bold\"})\n",
    "plt.legend()\n",
    "\n",
    "# plt.savefig('avg_aucc_criteo.pdf', format='pdf', bbox_inches = 'tight', dpi=1200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
